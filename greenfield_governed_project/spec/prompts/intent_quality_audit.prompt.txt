You are GitHub Copilot Chat running inside VS Code on a governed repository.

GOAL: Run an end-to-end audit for intent <INTENT_ID> that:
1) Confirms governance audit passes (`npm run audit:intent -- --intent-id <INTENT_ID>`)
2) Audits implementation quality by inspecting the actual repo code
3) Produces a machine-readable quality audit report with 10 improvements ranked by ROI (0–10), each with effort + risk
4) Saves the report under `status/audit/<INTENT_ID>/runs/<run_id>/quality_audit.json`
5) Ensures portal views will show it after refresh (run generate/guardrails)

Hard rules:
- Never hand-edit any `.md` files (generated).
- Only edit canonical sources: `spec/intents/*.json`, `spec/tasks/*.json`, `spec/requirements/**.json`, code under `apps/**`, `packages/**`, `scripts/**`, `tools/**`, `pipeline/**`.
- The audit report must be JSON (not Markdown).

First ask me these questions (one at a time, max 8 total):
1) What is `<INTENT_ID>`?
2) What is `<run_id>`? (If I don’t care, propose a `run_id` like `YYYYMMDD_HHMMSS`.)
3) Which code areas are in-scope for the quality audit? (default: everything under `pipeline/`, `apps/portal/`, `scripts/`, `tools/`)
4) Any constraints? (time budget, “no refactors”, performance vs correctness, etc.)

Then execute this process:

A) Run governance audit (must pass)
1) Run: `npm run audit:intent -- --intent-id <INTENT_ID> --out status/audit/<INTENT_ID>/runs/<run_id>/audit_report.json`
2) If it fails, stop and tell me exactly what to fix; do not proceed to quality audit until audit passes.

B) Quality audit (inspect the real code)
1) Read the intent spec: `spec/intents/<INTENT_ID>.json` and all referenced task specs `spec/tasks/<TASK_ID>.json`.
2) Inspect actual implementation files referenced by deliverables plus any obvious adjacent code.
3) Evaluate against these categories:
   - Correctness / trust-first behavior risks
   - Maintainability / clarity / cohesion
   - Testability (where tests should exist, even if none yet)
   - Performance + scalability bottlenecks
   - Security / safety (e.g., path handling, command execution, input validation)
   - Observability (logging quality, evidence capture usefulness)
4) Produce exactly 10 improvement items, ranked by ROI (0–10). Each item MUST include:
   - `id` (e.g. `IMP-001`)
   - `title`
   - `area` (e.g. `pipeline`, `portal`, `guardrails`, `generation`, `workflows`)
   - `roi_0_to_10` (number)
   - `effort` (`S`|`M`|`L`)
   - `risk` (`low`|`medium`|`high`)
   - `why` (1–3 sentences)
   - `proposed_changes` (bullet strings; concrete file/symbol pointers)

C) Write the report JSON (single file)
Create `status/audit/<INTENT_ID>/runs/<run_id>/quality_audit.json` with this schema:
{
  "type": "intent_quality_audit_report",
  "schema_version": 1,
  "intent_id": "<INTENT_ID>",
  "run_id": "<run_id>",
  "timestamp": "YYYY-MM-DDTHH:MM:SSZ",
  "scope": {
    "areas_in_scope": ["pipeline", "portal", "scripts", "tools"]
  },
  "audit_inputs": {
    "intent_spec_path": "spec/intents/<INTENT_ID>.json",
    "task_spec_paths": ["spec/tasks/TASK-...json"],
    "code_paths_reviewed": ["pipeline/src/...", "scripts/..."]
  },
  "summary": {
    "overall_health_0_to_10": 0,
    "top_risks": ["..."],
    "top_quick_wins": ["..."]
  },
  "improvements": [ /* exactly 10 items, sorted by roi desc */ ]
}

D) Validate + refresh surfaces
1) Run: `npm run generate`
2) Run: `npm run guardrails`
3) Tell me where the report file is and confirm it will appear in the portal after pressing Refresh on the intent page.

Output requirements (in chat):
- After writing the JSON file, show me only:
  - the final report path
  - the top 3 improvement titles + ROI/effort/risk
Do not paste the entire JSON into chat.

