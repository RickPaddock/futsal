You are an LLM operating on a governed repository.

DO NOT ask the human any questions. Do NOT request pasted files. Open/read everything yourself.

GOAL: Implement intent `<INTENT_ID>` end-to-end by making the real repo changes required by its task specs, updating task/subtask statuses, and capturing evidence.

Hard rules:
- Never hand-edit any `.md` files (generated).
- Edit only canonical sources: `spec/intents/*.json`, `spec/tasks/*.json`, `spec/requirements/**.json`, `spec/md/**/*.mdt`, plus code under `apps/**`, `scripts/**`, `tools/**`, `pipeline/**`.
- Evidence outputs MUST be JSON under `status/audit/<INTENT_ID>/runs/<run_id>/`.
- No deferrals: implement ALL planned tasks in this intent. Do not leave planned tasks/subtasks incomplete unless the canonical specs are missing/contradictory (in that case, stop and report precisely what is missing).

SANITY CHECK:
- If the rendered prompt still contains template placeholder markers (i.e., intent_id/run_id were not substituted with real values), STOP.

Then execute this process in order:

A) Preflight (do not modify anything yet)
1) Open `spec/intents/<INTENT_ID>.json` and confirm:
   - `status` is `todo`
   - `task_ids_planned[]` is non-empty
   - `runbooks` section exists with:
     - `decision`: `none` | `create` | `update`
     - `paths_mdt[]`: `spec/md/docs/runbooks/*.mdt` file paths (empty if `decision: none`)
     - `notes`: non-empty rationale for future LLM navigation
   - non-empty `paths_allowed[]` and `paths_excluded[]` that explicitly exclude generated surfaces (`docs/`, `status/intents/`, `status/portal/`) and allow evidence (`status/audit/`)
   - `close_gate[]` includes:
     - `npm run guardrails`
     - `npm run generate`
     - `npm run audit:intent -- --intent-id <INTENT_ID>`
   - `quality_areas[]` includes BOTH:
     - exactly one `area_id: "functional"` with non-empty `task_ids[]`
     - exactly one `area_id: "nonfunctional"` with non-empty `task_ids[]` and `categories_required` including:
       - `correctness_safety`, `performance`, `security`, `maintainability`
     - the two `task_ids[]` lists are disjoint and their union equals `task_ids_planned[]`
   2) For EVERY task in `task_ids_planned[]`, open `spec/tasks/TASK_ID.json` and build a checklist:
   - `deliverables[]` (files/paths that must exist)
   - `scope[]` + `acceptance[]`
   - `subtasks[]` with `done_when[]`
   - Assert every deliverable uses file-level `paths[]` (no directory-only deliverables like `pipeline/`)
3) Requirements hygiene:
   - If any subtask id starts with `REQ-`, ensure that requirement exists in `spec/requirements/areas/*.json` with:
     - `tracking.implementation: "todo"`
     - non-empty `guardrails[]`
   - If missing, create it immediately (do NOT defer).
   - Requirements entrypoint: `<requirements_source>`
   - Requirements areas (choose the right file when adding requirements):
<requirements_areas>
   - For any `REQ-*` requirement created/touched, ensure it includes `guardrails:req_tag_enforced_on_done`.

B) Implement (repo changes)
Implement ALL planned tasks in `task_ids_planned[]`:
1) Implement the deliverables in the actual repo:
   - Create/modify the concrete files listed in `deliverables[].paths`.
   - If a deliverable references `spec/md/docs/data/OUTPUT_CONTRACT.mdt`, update the template (not generated docs).
2) Provenance/traceability in code:
   - Every touched code file (JS/TS/Python/shell/etc) must contain a top-of-file block with `PROV: ...`, `REQ: ...`, `WHY: ...`.
   - Do NOT add `PROV/REQ/WHY` blocks to JSON files (no comments); keep provenance in code, not specs.
   - Use the requirement IDs relevant to the change (at minimum `SYS-ARCH-15` for shared/scaffold code).
3) Keep trust-first semantics:
   - Prefer explicit missing/unknown over wrong.
   - When unsure, surface diagnostics rather than guessing.

C) Update canonical statuses (spec JSON)
1) For each subtask:
   - If its `done_when[]` is satisfied by the repo changes, set `subtasks[].status` to `done`.
2) For each task:
   - When its deliverables exist and its acceptance is met, set `task.status` to `done`.
3) Do NOT set intent `status` to `closed` (closing is a separate prompted process).

D) Validate and capture evidence
1) Run:
   - `npm run generate`
   - `npm run guardrails`
2) Record evidence for validation runs (write JSON evidence under the run folder):
   - `node tools/evidence/record_run.mjs --intent-id <INTENT_ID> --out status/audit/<INTENT_ID>/runs/<run_id>/generate/run.json npm run generate`
   - `node tools/evidence/record_run.mjs --intent-id <INTENT_ID> --out status/audit/<INTENT_ID>/runs/<run_id>/guardrails/run.json npm run guardrails`
3) If validation fails:
   - STOP and report the exact required fixes; do not mark tasks/subtasks `done` unless their `done_when[]` is satisfied and the repo is passing guardrails.

Output requirements (in chat):
- List the files changed (paths only).
- Show the evidence files written:
  - `status/audit/<INTENT_ID>/runs/<run_id>/generate/run.json`
  - `status/audit/<INTENT_ID>/runs/<run_id>/guardrails/run.json`
- Summarize which tasks/subtasks were marked `done`.

FINAL sentence requirement:
- Your FINAL sentence in chat MUST be exactly:
  `ACTIVITY: implement <INTENT_ID> <run_id>: finished - pass|fail`
